import concurrent.futures
import threading

from retrying import retry
from config.config import GPT_MESSAGE, MAX_FILES, SUPPORTED_FILE_TYPES, IGNORE_FILE_TYPES, MAX_CONTENT_LENGTH, MAX_DIFF_LENGTH, MAX_SOURCE_LENGTH
from review_engine.abstract_handler import ReviewHandle
from utils.gitlab_parser import (filter_diff_content, add_context_to_diff, extract_diffs,
                                 get_comment_request_json, extract_comment_end_line)
from utils.logger import log
from utils.args_check import file_need_check
from utils.tools import batch
from review_engine.review_prompt import (REVIEW_SUMMARY_SETTING, FILE_DIFF_REVIEW_PROMPT, BATCH_SUMMARY_PROMPT,
                                         FINAL_SUMMARY_PROMPT,SUMMARY_OUTPUT_PROMPT)


def chat_review(changes, generate_review, *args, **kwargs):
    log.info(f'å¼€å§‹code review - å…± {len(changes)} ä¸ªæ–‡ä»¶')
    
    # åªè®°å½•éœ€è¦å®¡æŸ¥çš„æ–‡ä»¶
    reviewable_files = []
    for change in changes:
        file_path = change["new_path"]
        if file_need_check(file_path):
            reviewable_files.append(file_path)
    
    if reviewable_files:
        log.info(f'ğŸ“„ éœ€è¦å®¡æŸ¥çš„æ–‡ä»¶: {", ".join(reviewable_files)}')
    else:
        log.info('ğŸ“„ æ²¡æœ‰éœ€è¦å®¡æŸ¥çš„æ–‡ä»¶')
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        review_results = []
        result_lock = threading.Lock()

        def process_change(change):
            file_path = change["new_path"]
            log.info(f'ğŸ” å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}')
            try:
                result = generate_review(change, *args, **kwargs)
                log.info(f'âœ… å®Œæˆå¤„ç†æ–‡ä»¶: {file_path}')
                with result_lock:
                    review_results.append(result)
            except Exception as e:
                log.error(f'âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}')

        futures = []
        processed_count = 0
        for change in changes:
            if not file_need_check(change["new_path"]):
                log.info(f"{change['new_path']} éç›®æ ‡æ£€æµ‹æ–‡ä»¶ï¼")
                continue
            
            processed_count += 1
            futures.append(executor.submit(process_change, change))

        log.info(f'ğŸ“Š å°†å¤„ç† {processed_count} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {len(changes) - processed_count} ä¸ªæ–‡ä»¶')
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        concurrent.futures.wait(futures)

    log.info(f'âœ… Code review å®Œæˆï¼Œç”Ÿæˆäº† {len(review_results)} ä¸ªå®¡æŸ¥ç»“æœ')
    return "<details open><summary><h1>ä¿®æ”¹æ–‡ä»¶åˆ—è¡¨</h1></summary>" + "\n\n".join(review_results) +"</details>" if review_results else ""


def chat_review_summary(changes, model):
    log.info("å¼€å§‹ code review summary")
    file_diff_map = {}
    file_summary_map = {}
    summary_lock = threading.Lock()

    for change in changes:
        if change['new_path'] not in file_diff_map:
            if not file_need_check(change["new_path"]):
                continue
            file_diff_map[change['new_path']] = filter_diff_content(change['diff'])

    # å¯¹å•ä¸ªæ–‡ä»¶diffè¿›è¡Œæ€»ç»“
    with concurrent.futures.ThreadPoolExecutor() as executor:
        def process_summary(file, diff, model):
            summary = generate_diff_summary(file, diff, model)
            with summary_lock:
                file_summary_map[file] = summary

        futures = []
        for file, diff in file_diff_map.items():
            futures.append(executor.submit(process_summary, file, diff, model))
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        concurrent.futures.wait(futures)

    log.info("code diff reviewå®Œæˆï¼Œbatch summaryä¸­")
    summaries_content = ""
    batchsize = 8
    # åˆ†æ‰¹å¯¹å•æ–‡ä»¶summary è¿›è¡Œæ±‡æ€»
    for batch_data in batch(file_summary_map, batchsize):
        for file in batch_data:
            summaries_content += f"---\n{file}: {file_summary_map[file]}\n"
        batch_changesets_prompt = BATCH_SUMMARY_PROMPT.replace("$raw_summary", summaries_content)
        batch_summary_msg = [
            {"role": "system",
             "content": REVIEW_SUMMARY_SETTING
             },
            {"role": "user",
             "content": f"{batch_changesets_prompt}"
             }
        ]
        model.generate_text(batch_summary_msg)
        content = model.get_respond_content()
        if not content:
            log.error("LLMè¿”å›å†…å®¹ä¸ºç©º (chat_review_summary)")
            return ""
        summaries_content = content.replace('\n\n', '\n')

    # æ€»ç»“ç”Ÿæˆ summary å’Œ file summary è¡¨æ ¼
    final_summaries_content = SUMMARY_OUTPUT_PROMPT.replace("$summaries_content", summaries_content)
    final_summary_msg = [
        {"role": "system",
         "content": REVIEW_SUMMARY_SETTING
         },
        {"role": "user",
         "content": FINAL_SUMMARY_PROMPT
         },
        {"role": "user",
         "content": f"{final_summaries_content}"
         }
    ]
    summary_result = generate_diff_summary(model=model, messages=final_summary_msg)
    log.info("code diff review summaryå®Œæˆ")
    return summary_result+"\n\n---\n\n" if summary_result else ""

def chat_review_inline_comment(changes, model, merge_info):
    """è¡Œå†…comment"""
    log.info("å¼€å§‹code review inline comment")
    comment_results = []
    comment_lock = threading.Lock()
    diff_refs = merge_info['diff_refs']

    # å¯¹å•ä¸ªdiffå—ç”Ÿæˆ inline comment
    with concurrent.futures.ThreadPoolExecutor() as executor:
        def process_comment(diff, model, change, old_line_end, new_line_end):
            comment = generate_inline_comment(diff, model)
            comment_json = get_comment_request_json(comment, change, old_line_end, new_line_end ,diff_refs)
            with comment_lock:
                comment_results.append(comment_json)

        futures = []
        for change in changes:
            if not file_need_check(change["new_path"]):
                continue
            # è·å–å•æ–‡ä»¶ å¤šå¤„diffå†…å®¹
            diffs = extract_diffs(change['diff'])
            for diff in diffs:
                # diff = filter_diff_content(diff)
                old_line_end, new_line_end =  extract_comment_end_line(diff)
                futures.append(executor.submit(process_comment, diff, model, change, old_line_end, new_line_end))
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        concurrent.futures.wait(futures)

    log.info("inline comment å®Œæˆ")
    return comment_results if comment_results else None


@retry(stop_max_attempt_number=3, wait_fixed=60000)
def generate_inline_comment(diff, model):
    file_diff_prompt = FILE_DIFF_REVIEW_PROMPT.replace('$file_diff', diff)
    file_diff_prompt += "\n\nè¦æ±‚æ€»ç»“ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯„ä»·å°½å¯èƒ½å…¨é¢ä¸”ç²¾ç‚¼ï¼Œå­—æ•°ä¸è¶…è¿‡50å­—ã€‚"
    messages = [
        {"role": "system",
         "content": REVIEW_SUMMARY_SETTING
         },
        {
            "role": "user",
            "content": f"{file_diff_prompt}",
        },
    ]
    model.generate_text(messages)
    content = model.get_respond_content()
    if not content:
        log.error("LLMè¿”å›å†…å®¹ä¸ºç©º (generate_inline_comment)")
        return "comment: nothing obtained from LLM"
    response_content = content.replace('\n\n', '\n')
    if response_content:
        return response_content
    else:
        return "comment: nothing obtained from LLM"





@retry(stop_max_attempt_number=3, wait_fixed=60000)
def generate_diff_summary(file=None, diff=None, model=None, messages=None):
    file_diff_prompt =  FILE_DIFF_REVIEW_PROMPT.replace('$file_diff', diff) if diff else ""
    messages = [
        {"role": "system",
         "content": REVIEW_SUMMARY_SETTING
         },
        {
            "role": "user",
            "content": f"{file_diff_prompt}",
        },
    ] if messages is None else messages
    if model is None:
        return "summarize: model is None"
    model.generate_text(messages)
    content = model.get_respond_content()
    if not content:
        log.error("LLMè¿”å›å†…å®¹ä¸ºç©º (generate_diff_summary)")
        return "summarize: nothing obtained from LLM"
    response_content = content.replace('\n\n', '\n')
    if response_content:
        return response_content
    else:
        return "summarize: nothing obtained from LLM"


@retry(stop_max_attempt_number=3, wait_fixed=60000)
def generate_review_note_with_context(change, model, gitlab_fetcher, merge_info):
    try:
        # prepare
        new_path = change['new_path']
        log.info(f"ğŸ“„ å¼€å§‹å¤„ç†æ–‡ä»¶: {new_path}")
        log.info(f"ğŸ“‹ åˆ†æ”¯ä¿¡æ¯: {merge_info['source_branch']}")
        
        # è·å–æºä»£ç 
        source_code = gitlab_fetcher.get_file_content(change['new_path'], merge_info['source_branch'])
        
        # æ£€æŸ¥diffå†…å®¹
        diff_content = change['diff']
        if not diff_content:
            log.warning(f"âš ï¸ æ–‡ä»¶ {new_path} çš„diffå†…å®¹ä¸ºç©º")
            return ""
        
        # æ£€æŸ¥diffé•¿åº¦é™åˆ¶
        if len(diff_content) > MAX_DIFF_LENGTH:
            log.warning(f"âš ï¸ æ–‡ä»¶ {new_path} çš„diffå†…å®¹è¿‡é•¿ï¼Œå°†è¢«æˆªæ–­")
            diff_content = diff_content[:MAX_DIFF_LENGTH] + "\n\n... (å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
        
        # æ£€æŸ¥æºä»£ç é•¿åº¦é™åˆ¶
        if source_code and len(source_code) > MAX_SOURCE_LENGTH:
            log.warning(f"âš ï¸ æ–‡ä»¶ {new_path} çš„æºä»£ç è¿‡é•¿ï¼Œå°†ä¸æ·»åŠ ä¸Šä¸‹æ–‡")
            source_code = None
        
        # æ·»åŠ ä¸Šä¸‹æ–‡
        content = add_context_to_diff(diff_content, source_code)
        
        # æ£€æŸ¥æœ€ç»ˆå†…å®¹é•¿åº¦é™åˆ¶
        if content and len(content) > MAX_CONTENT_LENGTH:
            log.warning(f"âš ï¸ æ–‡ä»¶ {new_path} çš„æœ€ç»ˆå†…å®¹è¿‡é•¿ï¼Œå°†è¢«æˆªæ–­")
            content = content[:MAX_CONTENT_LENGTH] + "\n\n... (å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
        
        # æ£€æŸ¥æœ€ç»ˆå†…å®¹
        if not content or content.strip() == "":
            log.warning(f"âš ï¸ æ–‡ä»¶ {new_path} å¤„ç†åå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡å®¡æŸ¥")
            return ""
        
        # æ„å»ºæ¶ˆæ¯
        user_message = f"è¯·reviewè¿™éƒ¨åˆ†ä»£ç å˜æ›´ {content}"
        if len(user_message.strip()) <= 10:
            log.warning(f"âš ï¸ æ–‡ä»¶ {new_path} ç”¨æˆ·æ¶ˆæ¯è¿‡çŸ­ï¼Œè·³è¿‡å®¡æŸ¥")
            return ""
            
        messages = [
            {
                "role": "system",
                "content": GPT_MESSAGE
             },
            {
                "role": "user",
                "content": user_message,
            },
        ]
        
        # review
        log.info(f"ğŸ“¤ æ­£åœ¨å®¡æŸ¥æ–‡ä»¶: {new_path}")
        model.generate_text(messages)
        content = model.get_respond_content()
        if not content:
            log.error(f"LLMè¿”å›å†…å®¹ä¸ºç©º (generate_review_note_with_context) for {new_path}")
            return ""
        response_content = content.replace('\n\n', '\n')
        total_tokens = model.get_respond_tokens()

        # response
        review_note = f"<details><summary>ğŸ“š<strong><code>{new_path}</code></strong></summary>\
        <div>({total_tokens} tokens) AI review æ„è§å¦‚ä¸‹:</div> \n\n\n\n {response_content} \n\n <hr><hr></details>"

        # review_note += f'# ğŸ“š`{new_path}`' + '\n\n'
        # review_note += f'({total_tokens} tokens) {"AI review æ„è§å¦‚ä¸‹:"}' + '\n\n'
        # review_note += response_content + "\n\n---\n\n---\n\n"
        
        log.info(f'âœ… æ–‡ä»¶ {new_path} å®¡æŸ¥å®Œæˆ')
        return review_note
    
    except Exception as e:
        log.error(f"LLM Review error:{e}")
        return ""


class MainReviewHandle(ReviewHandle):
    def merge_handle(self, gitlabMergeRequestFetcher, gitlabRepoManager, hook_info, reply, model):
        changes = gitlabMergeRequestFetcher.get_changes()
        merge_info = gitlabMergeRequestFetcher.get_info()
        self.default_handle(changes, merge_info, hook_info, reply, model, gitlabMergeRequestFetcher)


    def default_handle(self, changes, merge_info, hook_info, reply, model, gitlab_fetcher):
        if changes and len(changes) <= MAX_FILES:
            review_summary = chat_review_summary(changes, model)
            review_info = chat_review(changes, generate_review_note_with_context, model, gitlab_fetcher, merge_info)
            review_info = review_summary + review_info

            review_inline_comments = chat_review_inline_comment(changes, model, merge_info)

            if review_info:
                reply.add_reply({
                    'content': review_info,
                    'msg_type': 'MAIN, SINGLE',
                    'target': 'all',
                })
                reply.add_reply({
                    'title': '__MAIN_REVIEW__',
                    'content': (
                        f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                        f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                        f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                        f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                        f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n\n"
                        f"### å˜æ›´è¯¦æƒ…\n"
                        f"- **ä¿®æ”¹æ–‡ä»¶ä¸ªæ•°**: `{len(changes)}`\n"
                        f"- **Code Review çŠ¶æ€**: âœ…\n"
                    ),
                    'target': 'dingtalk',
                    'msg_type': 'MAIN, SINGLE',
                })
            else:
                reply.add_reply({
                    'title': '__MAIN_REVIEW__',
                    'content': (
                        f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                        f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                        f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                        f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                        f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n\n"
                        f"### å˜æ›´è¯¦æƒ…\n"
                        f"- **ä¿®æ”¹æ–‡ä»¶ä¸ªæ•°**: `{len(changes)}`\n"
                        f"- **å¤‡æ³¨**: å­˜åœ¨å·²ç»æäº¤çš„ MRï¼Œæ‰€æœ‰æ–‡ä»¶å·²è¿›è¡Œ MR\n"
                        f"- **Code Review çŠ¶æ€**: pass âœ…\n"
                    ),
                    'target': 'dingtalk',
                    'msg_type': 'MAIN, SINGLE',
                })

            if review_inline_comments:
                for comment in review_inline_comments:
                    reply.add_comment({
                        'content': comment,
                        'target': 'gitlab',
                        'msg_type': 'COMMENT',
                    })




        elif changes and len(changes) > MAX_FILES:
            reply.add_reply({
                'title': '__MAIN_REVIEW__',
                'content': (
                    f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                    f"### å¤‡æ³¨\n"
                    f"ä¿®æ”¹ `{len(changes)}` ä¸ªæ–‡ä»¶ > 50 ä¸ªæ–‡ä»¶ï¼Œä¸è¿›è¡Œ Code Review âš ï¸\n\n"
                    f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                    f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                    f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                    f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n"
                ),
                'target': 'dingtalk',
                'msg_type': 'MAIN, SINGLE',
            })

        else:
            log.error(f"è·å–merge_requestä¿¡æ¯å¤±è´¥ï¼Œproject_id: {hook_info['project']['id']} |"
                      f" merge_iid: {hook_info['object_attributes']['iid']} | merge_info: {merge_info}")


